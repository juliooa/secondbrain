{
    "models": [
        {
            "filename": "open_llama_3b-q4_0-ggjt.bin",
            "name": "rustformers/open-llama-ggml",
            "url": "https://huggingface.co/rustformers/open-llama-ggml/resolve/main/open_llama_3b-q4_0-ggjt.bin",
            "arquitecture": "llama",
            "image": "",
            "prompt_template":"[[message]]",
            "hf_link":"https://huggingface.co/rustformers/open-llama-ggml",
            "size":"1.93Gb"
          },
          {
            "filename": "RedPajama-INCITE-7B-Instruct-q4_0-ggjt.bin",
            "name": "rustformers/redpajama-7b-ggml",
            "url": "https://huggingface.co/rustformers/redpajama-7b-ggml/resolve/main/RedPajama-INCITE-7B-Instruct-q4_0-ggjt.bin",
            "arquitecture": "gptneox",
            "image": "",
            "prompt_template":"[[message]]",
            "hf_link":"https://huggingface.co/rustformers/redpajama-7b-ggml",
            "size":"3.86Gb"
          },
          {
            "filename": "gpt4all-j-q4_0.bin",
            "name": "rustformers/gpt4all-j-ggml",
            "url": "https://huggingface.co/rustformers/gpt4all-j-ggml/resolve/main/gpt4all-j-q4_0.bin",
            "arquitecture": "gptj",
            "image": "",
            "prompt_template":"[[message]]",
            "hf_link":"https://huggingface.co/rustformers/gpt4all-j-ggml",
            "size":"3.41Gb"
          },
          {
            "filename": "mpt-7b-instruct-q4_0.bin",
            "name": "rustformers/mpt-7b-ggml",
            "url": "https://huggingface.co/rustformers/mpt-7b-ggml/resolve/main/mpt-7b-instruct-q4_0.bin",
            "arquitecture": "gptj",
            "image": "",
            "prompt_template":"[[message]]",
            "hf_link":"https://huggingface.co/rustformers/mpt-7b-ggml",
            "size":"3.74Gb"
          },
          {
            "filename": "stablelm-tuned-alpha-7b-q4_0.bin",
            "name": "rustformers/stablelm-ggml",
            "url": "https://huggingface.co/rustformers/stablelm-ggml/resolve/main/stablelm-tuned-alpha-7b-q4_0.bin",
            "arquitecture": "gptneox",
            "image": "",
            "prompt_template":"[[message]]",
            "hf_link":"https://huggingface.co/rustformers/stablelm-ggml",
            "size":"4.43Gb"
          },
          {
            "filename": "Samantha-7B.ggmlv3.q4_1.bin",
            "name": "TheBloke/Samantha-7B-GGML",
            "url": "https://huggingface.co/TheBloke/Samantha-7B-GGML/resolve/main/Samantha-7B.ggmlv3.q4_1.bin",
            "arquitecture": "llama",
            "image": "",
            "prompt_template":"You are Samantha, a sentient AI.\nUSER: [[message]]\nASSISTANT:",
            "hf_link":"https://huggingface.co/TheBloke/Samantha-7B-GGML",
            "size":"4.21Gb"
          },
          {
            "filename": "Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0.bin",
            "name": "TheBloke/Wizard-Vicuna-7B-Uncensored-GGML",
            "url": "https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML/resolve/main/Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0.bin",
            "arquitecture": "llama",
            "image": "",
            "prompt_template":"USER: [[message]]\nASSISTANT:",
            "hf_link":"https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML",
            "size":"3.79Gb"
          }

    ]
}